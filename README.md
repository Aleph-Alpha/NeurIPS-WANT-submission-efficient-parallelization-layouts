### Excel sheets and scripts for NeurIPS [WANT](https://want-ai-hpc.github.io/neurips2023/callforpapers) workshop publication: 
### ["Efficient Parallelization Layouts for Large-Scale Distributed Model Training"](https://arxiv.org/abs/2311.05610)

### Cite Us
To cite this project, you can use the following BibTeX citation.
```
@misc{hagemann2023efficient,
      title={Efficient Parallelization Layouts for Large-Scale Distributed Model Training}, 
      author={Johannes Hagemann and Samuel Weinbach and Konstantin Dobler and Maximilian Schall and Gerard de Melo},
      year={2023},
      eprint={2311.05610},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```